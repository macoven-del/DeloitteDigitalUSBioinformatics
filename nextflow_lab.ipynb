{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17120e37",
   "metadata": {},
   "source": [
    "# Introduction to Nextflow Lab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cd1b9dc",
   "metadata": {},
   "source": [
    "### 1. Setup your environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca7ad1bd",
   "metadata": {},
   "source": [
    "Install mambaforge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105ea1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -L -O https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-$(uname)-$(uname -m).sh\n",
    "! bash Mambaforge-$(uname)-$(uname -m).sh -b -p $HOME/mambaforge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659750b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm Mambaforge-Linux*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca089dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to your path, you need to redo this each session. If your windows times out, rerun this.\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + os.environ[\"HOME\"]+\"/mambaforge/bin\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43c4fe6d",
   "metadata": {},
   "source": [
    "Install nf-core tools, nextflow, and sra tools to download data from the SRA database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c4b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mamba install -c bioconda nf-core nextflow sra-tools -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e19e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nextflow -version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0247f3fe",
   "metadata": {},
   "source": [
    "### 2. Clone NF Core Repositories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d315611c",
   "metadata": {},
   "source": [
    "Download an example nf-core repo and look over the organization. Look at the main.nf, the workflows dir, and the modules dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69d71da",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/nf-core/rnaseq.git"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85b069a7",
   "metadata": {},
   "source": [
    "### 3. Run RNAseq and look at the work dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eacb225",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nextflow run nf-core/rnaseq -profile test,docker --outdir rnaseq_out/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30519a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls work/e4/69d7f6*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2dc6cedd",
   "metadata": {},
   "source": [
    "### 4. Create an nf-core template repository"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cacce74",
   "metadata": {},
   "source": [
    "Now let's create a template repo using the nf-core template and we will start building out a workflow using that template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da25510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nf-core create -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39cf15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nf-core create -n nfcoretutorial -o nfcore-tutorial -d 'This repo is a demo of the nf core template' -a 'William Welch Deloitte' --plain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b48002c",
   "metadata": {},
   "source": [
    "Now we have a template. The template has a lot of extra stuff, so if you were doing this for a production pipeline, you would need to go through each directory carefully and clean things up. \n",
    "The goal now is build a simple variant calling workflow for MPOX viral sequences. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89f8cebf",
   "metadata": {},
   "source": [
    "### 5. Set up your input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c406a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd nfcore-tutorial-template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfb0b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp ../assets/ON56* assets/\n",
    "! cp ../assets/samplesheet.csv assets/\n",
    "! cp ../assets/illumina_adapters.fasta assets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d4c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! fasterq-dump -f -O data -e 8 SRR23873775"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794386fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip data/SRR23873775_1.fastq\n",
    "!gzip data/SRR23873775_2.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f552f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls data/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46b984b5",
   "metadata": {},
   "source": [
    "### 6. Add your first modules\n",
    "Instructions can be [found here](https://nf-co.re/docs/contributing/tutorials/adding_modules_to_pipelines).\n",
    "Modules make up the building blocks of a workflow. Here we will add a few modules to create a workflow.\n",
    "+ Clean our data with fastp\n",
    "+ Index our reference with bwa\n",
    "+ Align to reference sequence with bwa mem\n",
    "+ Call variants with IVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032638a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nf-core modules install fastp\n",
    "! nf-core modules install bwa/index\n",
    "! nf-core modules install bwa/mem\n",
    "! nf-core modules install ivar/variants"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae638dcb",
   "metadata": {},
   "source": [
    "Note that the module files under added under modules/nf-core/. Along the same lines, if you need to develop a custom module to run a Python or bash script, you can do that by creating a module that calls your script and putting it under modules/local.\n",
    "\n",
    "The output also gives you the include statements you need to add to the workflow file: \n",
    "```\n",
    "include { FASTP                       } from '../modules/nf-core/fastp/main'\n",
    "include { BWA_INDEX                   } from '../modules/nf-core/bwa/index/main'\n",
    "include { BWA_MEM                     } from '../modules/nf-core/bwa/mem/main'\n",
    "include { IVAR_VARIANTS               } from '../modules/nf-core/ivar/variants/main'\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7dd0f72b",
   "metadata": {},
   "source": [
    "Next, we need to call these modules from within the workflow. Add the following to your workflow file under FASTQC like this:\n",
    "```\n",
    "    //\n",
    "    // MODULE: Run FastQC\n",
    "    //\n",
    "    FASTQC (\n",
    "        INPUT_CHECK.out.reads\n",
    "    )\n",
    "    ch_versions = ch_versions.mix(FASTQC.out.versions.first())\n",
    "\n",
    "    CUSTOM_DUMPSOFTWAREVERSIONS (\n",
    "        ch_versions.unique().collectFile(name: 'collated_versions.yml')\n",
    "    )\n",
    "\n",
    "    //\n",
    "    // MODULE: Run Fastp\n",
    "    //\n",
    "    FASTP (\n",
    "        READS\n",
    "    )\n",
    "    ch_versions = ch_versions.mix(FASTP.out.versions.first())\n",
    "\n",
    "    CUSTOM_DUMPSOFTWAREVERSIONS (\n",
    "        ch_versions.unique().collectFile(name: 'collated_versions.yml')\n",
    "    )\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c938b73a",
   "metadata": {},
   "source": [
    "Note what we are doing here. We call the module, then we give it the inputs required in the modules/nf-core/fastp/main.nf file. Then for output channels, we can look at the same main.nf file and see what is emitted. In this case, we want the trimmed reads, so it will be FASTP.out.reads. Now try and do the same thing for BWA_INDEX,BWA_MEM, and IVAR_VARIANTS. If you get stuck, we have the answers below. If you get an error like this `Process `NFCORE_TUTORIAL:TUTORIAL:IVAR_VARIANTS` declares 5 input channels but 1 were specified`, it just means that you need to add more input channels in the workflow declaration, because the main.nf for that process is expecting more values. In some cases an output is optional, and so you need to specify `true` or `false` in the declaration block of the workflow.\n",
    "\n",
    "\n",
    "<details id=0>\n",
    "<summary><h2>Answers</h2></summary>\n",
    "\n",
    "    //\n",
    "    // MODULE: Run bwa index\n",
    "    //\n",
    "    BWA_INDEX (\n",
    "        params.reference\n",
    "    )\n",
    "    ch_versions = ch_versions.mix(BWA_INDEX.out.versions.first())\n",
    "    ch_index = BWA_INDEX.out.index\n",
    "\n",
    "    CUSTOM_DUMPSOFTWAREVERSIONS (\n",
    "        ch_versions.unique().collectFile(name: 'collated_versions.yml')\n",
    "    )\n",
    "    \n",
    "    //\n",
    "    // MODULE: Run bwa mem\n",
    "    //\n",
    "    BWA_MEM (\n",
    "        ch_index\n",
    "    )\n",
    "    ch_versions = ch_versions.mix(BWA_MEM.out.versions.first())\n",
    "    ch_bam = BWA_MEM.out.bam\n",
    "\n",
    "    CUSTOM_DUMPSOFTWAREVERSIONS (\n",
    "        ch_versions.unique().collectFile(name: 'collated_versions.yml')\n",
    "    )\n",
    "\n",
    "    //\n",
    "    // MODULE: Run IVAR Variants\n",
    "    //\n",
    "    IVAR_VARIANTS (\n",
    "        ch_bam\n",
    "    )\n",
    "    ch_versions = ch_versions.mix(IVAR_VARIANTS.out.versions.first())\n",
    "    ch_bam = BWA_MEM.out.bam\n",
    "\n",
    "    CUSTOM_DUMPSOFTWAREVERSIONS (\n",
    "        ch_versions.unique().collectFile(name: 'collated_versions.yml')\n",
    "    )\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6439bb8d",
   "metadata": {},
   "source": [
    "You also need to add a few parameters to get these modules to work. You can add default params in the nextflow.config file to point to the files we moved into the assets dir. Your References section should look like this: \n",
    "```\n",
    "    // References\n",
    "    fasta                      = \"${launchDir}/assets/ON563414_mpox_reference.fasta\"\n",
    "    fai                        = \"${launchDir}/assets/ON563414_mpox_reference.fasta.fai\"\n",
    "    gff                        = \"${launchDir}/assets/ON563414_mpox_reference.gff\"\n",
    "    adapters                   = \"${launchDir}/assets/adapters.fasta\"\n",
    "    genome                     = null\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58364082",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ecfc657",
   "metadata": {},
   "source": [
    "Also add the following output channel after INPUT_CHECK\n",
    "\n",
    "````\n",
    "ch_reads=INPUT_CHECK.out.reads\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9162813c",
   "metadata": {},
   "source": [
    "### 7. Run our workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nextflow run main.nf -profile docker --input assets/samplesheet.csv --outdir results -resume"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45346a33",
   "metadata": {},
   "source": [
    "### 8. Troubleshoot our workflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "193bc230",
   "metadata": {},
   "source": [
    "You should get an error for FASTP about a mismatch in the number of input channels. This is because, the module/main.nf file requires 4 input channels, but you only specify one in the main workflow. So you need to edit nfcoretutorial.nf to give four channels. For example, the module file for fastq looks like this:\n",
    "```\n",
    "    tuple val(meta), path(reads)\n",
    "    path  adapter_fasta\n",
    "    val   save_trimmed_fail\n",
    "    val   save_merged\n",
    "```\n",
    "You need to give the trimmer fasta and then just say false false for the other two. Like this and then rerun the cell above:\n",
    "```\n",
    "FASTP (\n",
    "        ch_reads,\n",
    "        params.adapters,\n",
    "        false,\n",
    "        false\n",
    "    )\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d41a22a6",
   "metadata": {},
   "source": [
    "You need to change BWA to this input chnannel, changing `reference` to `fasta`:\n",
    "\n",
    "BWA_INDEX (\n",
    "        params.fasta\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa9f21fe",
   "metadata": {},
   "source": [
    "Make sure you only have one block at the very end of the following:\n",
    "CUSTOM_DUMPSOFTWAREVERSIONS (\n",
    "        ch_versions.unique().collectFile(name: 'collated_versions.yml')\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0dd3c42",
   "metadata": {},
   "source": [
    "If you get an issue with the versions like related to 'FIRST' then just replace the version lines like this: \n",
    "    `ch_versions = ch_versions.mix(BWA_MEM.out.versions)`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67fcbc14",
   "metadata": {},
   "source": [
    "### 9. Giving up in despair and just using the premade nfcore template\n",
    "\n",
    "If you are running in codespaces we are memory limited, and thus the pipeline will never work unfortunately. We included a more complete version of the workflow called nfcore-tutorial-template that will run better but still not all the way through. That said, hopefully at this point you have been able to get a better understanding of how the pieces of a workflow fit together. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66871663",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
